import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv(r"C:\Users\Anuja Shetty\Downloads\Mall_Customers.csv")

df.head()

df.tail()

df.shape

df.columns

df.drop("CustomerID",axis=1,inplace=True)

df

print("Missing values:")
df.isnull().sum()

df.describe()

df.info()

df.nunique()

print(df.dtypes)

# Modern Pandas: Ignores non-numeric columns
df.corr(numeric_only=True)

# Or, manually select columns:
numeric_cols = df.select_dtypes(include=['number']).columns
df[numeric_cols].corr()

print(df.columns)

# Selects all columns that are integers or floats
numeric_df = df.select_dtypes(include=['number'])
plt.figure(figsize=(7,5))
# Calculate correlation on the numeric-only subset
sns.heatmap(numeric_df.corr(), annot=True, cmap='RdYlGn')
plt.show()

df.hist(bins = 50,figsize = (10,6))

df['Genre'].value_counts().plot(kind='pie',figsize=(5,5),autopct='%1.1f%%')
plt.title("Total Gender Count")
plt.show()

sns.pairplot(df,hue="Genre");

sns.set(style = 'whitegrid')
sns.scatterplot(y = 'Spending Score (1-100)',x ='Annual Income (k$)',data = df,h
plt.title('Iris Dataset')
plt.show()

from sklearn.preprocessing import LabelEncoder
from sklearn import metrics
le = LabelEncoder()
df["Genre"] = le.fit_transform(df["Genre"])

df

data = df.copy()
x = data.iloc[:,[2,3]]

from sklearn.cluster import KMeans
wcss = []
for i in range(1,11):
kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
kmeans.fit(x)


# Assuming this is inside a loop structure
wcss.append(kmeans.inertia_)
# Ensure this print statement is indented correctly for its context (e.g., insid
# If it's outside the loop, remove all leading spaces.
print('k:', i, "-> wcss:", kmeans.inertia_)

print(len(range(1, 11))) # Should print 10
print(len(wcss))

#Taking 5 clusters
km1=KMeans(n_clusters=5)
#Fitting the input data
km1.fit(data)
#predicting the labels of the input data
y=km1.predict(data)
#adding the labels to a column named label
data["label"] = y
#The new dataframe with the clustering done
data.head()

#Scatterplot of the clusters
plt.figure(figsize=(6,4))
sns.scatterplot(x = 'Annual Income (k$)',y = 'Spending Score (1-100)',hue="label
palette=['green','brown','orange','red','dodgerblue'],data = data )
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Spending Score (1-100) vs Annual Income (k$)')
plt.show()

X=data.iloc[:,:4]
y=data.iloc[:,-1]

print('X_train shape:', X_train.shape, 'y_train shape:', y_train.shape)
print('X_test shape:', X_test.shape, 'y_test shape:', y_test.shape)


from sklearn.cluster import KMeans
km=KMeans(n_clusters=5)
km.fit(X_train)
#predicting the target value from the model for the samples
y_train_km = km.predict(X_train)
y_test_km = km.predict(X_test)

from sklearn.metrics.cluster import adjusted_rand_score
acc_train_gmm = adjusted_rand_score(y_train,y_train_km)
acc_test_gmm = adjusted_rand_score(y_test,y_test_km)
print("K mean : Accuracy on training Data: {:.3f}".format(acc_train_gmm))
print("K mean : Accuracy on test Data: {:.3f}".format(acc_test_gmm))

data = df.copy()
data = data.iloc[:,[2,3]]
data

sns.scatterplot(x="Annual Income (k$)",y="Spending Score (1-100)",data = data );

import scipy.cluster.hierarchy as shc
dendrogram = shc.dendrogram(shc.linkage(data,method="ward"))
plt.title("dendrogram Plot")
plt.xlabel("Customer")
plt.ylabel("Eclidean Distance")
plt.grid(False)

from sklearn.cluster import AgglomerativeClustering
agc = AgglomerativeClustering(n_clusters=5)
data["label"] = agc.fit_predict(data)
data

sns.scatterplot(x = 'Annual Income (k$)',y = 'Spending Score (1-100)',hue="label
palette=['green','brown','orange','red','dodgerblue'],data = data )

plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Spending Score (1-100) vs Annual Income (k$)')
plt.show()